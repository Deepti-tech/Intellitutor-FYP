{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Facial expression for emotion detection has always been an easy task for humans, but achieving the same task with a computer algorithm is quite challenging. With the recent advancement in computer vision and machine learning, it is possible to detect emotions from images.\n","\n","### In this project we use a technique called facial emotion recognition using convolutional neural networks **(FERC)**\n","\n","### The FERC is based on two-part :-\n","### 1. convolutional neural network (CNN): The first-part removes the background from the picture, \n","### 2. The second part concentrates on the facial feature vector extraction"]},{"cell_type":"markdown","metadata":{},"source":["# Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-22T05:23:07.429475Z","iopub.status.busy":"2021-06-22T05:23:07.428984Z","iopub.status.idle":"2021-06-22T05:23:14.323366Z","shell.execute_reply":"2021-06-22T05:23:14.322206Z","shell.execute_reply.started":"2021-06-22T05:23:07.429376Z"},"trusted":true},"outputs":[],"source":["## General Libraries\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import os\n","\n","## Deep Learning Libraries\n","\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\n","from keras.layers import Conv2D,MaxPooling2D\n","from keras.preprocessing.image import load_img, img_to_array"]},{"cell_type":"markdown","metadata":{},"source":["# Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-22T05:30:08.979513Z","iopub.status.busy":"2021-06-22T05:30:08.979016Z","iopub.status.idle":"2021-06-22T05:30:14.680245Z","shell.execute_reply":"2021-06-22T05:30:14.679233Z","shell.execute_reply.started":"2021-06-22T05:30:08.979479Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv('../Archive-Version-1/Dataset/fer2013.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-22T05:30:32.170024Z","iopub.status.busy":"2021-06-22T05:30:32.169637Z","iopub.status.idle":"2021-06-22T05:30:32.182553Z","shell.execute_reply":"2021-06-22T05:30:32.18105Z","shell.execute_reply.started":"2021-06-22T05:30:32.169992Z"},"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-22T05:30:32.279318Z","iopub.status.busy":"2021-06-22T05:30:32.27898Z","iopub.status.idle":"2021-06-22T05:30:32.286391Z","shell.execute_reply":"2021-06-22T05:30:32.284747Z","shell.execute_reply.started":"2021-06-22T05:30:32.279289Z"},"trusted":true},"outputs":[],"source":["## shape of the dataset\n","\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-22T05:30:32.289848Z","iopub.status.busy":"2021-06-22T05:30:32.289261Z","iopub.status.idle":"2021-06-22T05:30:32.31376Z","shell.execute_reply":"2021-06-22T05:30:32.312456Z","shell.execute_reply.started":"2021-06-22T05:30:32.289801Z"},"trusted":true},"outputs":[],"source":["## checking for null values\n","\n","df.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["So, in the dataset there is not any missing values."]},{"cell_type":"markdown","metadata":{},"source":["# count of each classes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-22T06:02:39.462823Z","iopub.status.busy":"2021-06-22T06:02:39.462434Z","iopub.status.idle":"2021-06-22T06:02:39.473774Z","shell.execute_reply":"2021-06-22T06:02:39.472291Z","shell.execute_reply.started":"2021-06-22T06:02:39.462792Z"},"trusted":true},"outputs":[],"source":["df['emotion'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["# Path of input Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-22T05:30:32.317195Z","iopub.status.busy":"2021-06-22T05:30:32.31669Z","iopub.status.idle":"2021-06-22T05:30:32.322545Z","shell.execute_reply":"2021-06-22T05:30:32.320807Z","shell.execute_reply.started":"2021-06-22T05:30:32.317151Z"},"trusted":true},"outputs":[],"source":["train_data_dir = '../Archive-Version-1/Dataset/train'\n","validation_data_dir = '../Archive-Version-1/Dataset/test'"]},{"cell_type":"markdown","metadata":{},"source":["# Displaying Images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-22T05:30:32.325728Z","iopub.status.busy":"2021-06-22T05:30:32.32498Z","iopub.status.idle":"2021-06-22T05:30:34.028296Z","shell.execute_reply":"2021-06-22T05:30:34.027145Z","shell.execute_reply.started":"2021-06-22T05:30:32.325521Z"},"trusted":true},"outputs":[],"source":["# size of the image: 48*48 pixels\n","picture_size = 48\n","\n","# input path for the images\n","folder_path = \"../input/emotion-detection-fer/train\"\n","\n","expression = 'sad'\n","\n","plt.figure(figsize= (12,12))\n","for i in range(1, 10, 1):\n","    plt.subplot(3,3,i)\n","    img = load_img(folder_path+ '/' +expression+\"/\"+\n","                  os.listdir(folder_path+ '/' + expression)[i], target_size=(picture_size, picture_size))\n","    plt.imshow(img)   \n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Model Training and Validation Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-22T05:30:34.030098Z","iopub.status.busy":"2021-06-22T05:30:34.029684Z","iopub.status.idle":"2021-06-22T05:30:34.035853Z","shell.execute_reply":"2021-06-22T05:30:34.034393Z","shell.execute_reply.started":"2021-06-22T05:30:34.030036Z"},"trusted":true},"outputs":[],"source":["## Defining different classes of emotion\n","num_classes = 7\n","\n","## Define image size\n","img_rows,img_cols = 48,48\n","\n","## Deifne the batch\n","batch_size = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-22T05:30:34.038335Z","iopub.status.busy":"2021-06-22T05:30:34.037792Z","iopub.status.idle":"2021-06-22T05:31:11.611542Z","shell.execute_reply":"2021-06-22T05:31:11.610482Z","shell.execute_reply.started":"2021-06-22T05:30:34.038294Z"},"trusted":true},"outputs":[],"source":["train_datagen = ImageDataGenerator(\n","\t\t\t\t\trescale=1./255,\n","\t\t\t\t\trotation_range=30,\n","\t\t\t\t\tshear_range=0.3,\n","\t\t\t\t\tzoom_range=0.3,\n","\t\t\t\t\twidth_shift_range=0.4,\n","\t\t\t\t\theight_shift_range=0.4,\n","\t\t\t\t\thorizontal_flip=True,\n","\t\t\t\t\tfill_mode='nearest')\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","\t\t\t\t\ttrain_data_dir,\n","\t\t\t\t\tcolor_mode='grayscale',\n","\t\t\t\t\ttarget_size=(img_rows,img_cols),\n","\t\t\t\t\tbatch_size=batch_size,\n","\t\t\t\t\tclass_mode='categorical',\n","\t\t\t\t\tshuffle=True)\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","\t\t\t\t\t\t\tvalidation_data_dir,\n","\t\t\t\t\t\t\tcolor_mode='grayscale',\n","\t\t\t\t\t\t\ttarget_size=(img_rows,img_cols),\n","\t\t\t\t\t\t\tbatch_size=batch_size,\n","\t\t\t\t\t\t\tclass_mode='categorical',\n","\t\t\t\t\t\t\tshuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Model Building"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-06-22T05:31:11.613786Z","iopub.status.busy":"2021-06-22T05:31:11.613308Z","iopub.status.idle":"2021-06-22T05:31:14.486618Z","shell.execute_reply":"2021-06-22T05:31:14.485592Z","shell.execute_reply.started":"2021-06-22T05:31:11.613745Z"},"trusted":true},"outputs":[],"source":["\n","model = Sequential()\n","\n","# Block-1\n","\n","model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","\n","# Block-2 \n","\n","model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","\n","# Block-3\n","\n","model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","\n","# Block-4 \n","\n","model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","\n","# Block-5\n","\n","model.add(Flatten())\n","model.add(Dense(64,kernel_initializer='he_normal'))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","\n","# Block-6\n","\n","model.add(Dense(64,kernel_initializer='he_normal'))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","\n","# Block-7\n","\n","model.add(Dense(num_classes,kernel_initializer='he_normal'))\n","model.add(Activation('softmax'))\n","\n","print(model.summary())\n","\n","from keras.optimizers import RMSprop,SGD,Adam\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","\n","checkpoint = ModelCheckpoint('Emotion_little_vgg.h5',\n","                             monitor='val_loss',\n","                             mode='min',\n","                             save_best_only=True,\n","                             verbose=1)\n","\n","earlystop = EarlyStopping(monitor='val_loss',\n","                          min_delta=0,\n","                          patience=3,\n","                          verbose=1,\n","                          restore_best_weights=True\n","                          )\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n","                              factor=0.2,\n","                              patience=3,\n","                              verbose=1,\n","                              min_delta=0.0001)\n","\n","callbacks = [earlystop,checkpoint,reduce_lr]\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer = Adam(lr=0.001),\n","              metrics=['accuracy'])\n","\n","nb_train_samples = 24320\n","nb_validation_samples = 3072\n","epochs=40\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-22T05:31:14.488861Z","iopub.status.busy":"2021-06-22T05:31:14.488362Z","iopub.status.idle":"2021-06-22T06:00:07.059071Z","shell.execute_reply":"2021-06-22T06:00:07.057974Z","shell.execute_reply.started":"2021-06-22T05:31:14.488817Z"},"trusted":true},"outputs":[],"source":["history=model.fit_generator(\n","                train_generator,\n","                steps_per_epoch=nb_train_samples//batch_size,\n","                epochs=epochs,\n","                callbacks=callbacks,\n","                validation_data=validation_generator,\n","                validation_steps=nb_validation_samples//batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["# Accuracy and Performance"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-22T06:00:07.06397Z","iopub.status.busy":"2021-06-22T06:00:07.063653Z","iopub.status.idle":"2021-06-22T06:00:07.484227Z","shell.execute_reply":"2021-06-22T06:00:07.48301Z","shell.execute_reply.started":"2021-06-22T06:00:07.063939Z"},"trusted":true},"outputs":[],"source":["plt.style.use('dark_background')\n","\n","plt.figure(figsize=(20,10))\n","plt.subplot(1, 2, 1)\n","plt.suptitle('Optimizer : Adam', fontsize=10)\n","plt.ylabel('Loss', fontsize=16)\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.legend(loc='upper right')\n","\n","plt.subplot(1, 2, 2)\n","plt.ylabel('Accuracy', fontsize=16)\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":155246,"sourceId":356254,"sourceType":"datasetVersion"},{"datasetId":786787,"sourceId":1351797,"sourceType":"datasetVersion"},{"datasetId":1028436,"sourceId":1732825,"sourceType":"datasetVersion"},{"datasetId":1424338,"sourceId":2358579,"sourceType":"datasetVersion"}],"dockerImageVersionId":30096,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
